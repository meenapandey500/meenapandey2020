{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensembling Technique\n",
    "#1. Naive Agrregation\n",
    "#A. Hard Voting    and B.Soft Voting\n",
    "\n",
    "#here classification dataset bank.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2343</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1270</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2476</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>673</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0   59    0        1          1        0     2343        1     0        2   \n",
       "1   56    0        1          1        0       45        0     0        2   \n",
       "2   41    9        1          1        0     1270        1     0        2   \n",
       "3   55    7        1          1        0     2476        1     0        2   \n",
       "4   54    0        1          2        0      184        0     0        2   \n",
       "\n",
       "   day  month  duration  campaign  pdays  previous  poutcome  deposit  \n",
       "0    5      8      1042         1     -1         0         3        1  \n",
       "1    5      8      1467         1     -1         0         3        1  \n",
       "2    5      8      1389         1     -1         0         3        1  \n",
       "3    5      8       579         1     -1         0         3        1  \n",
       "4    5      8       673         2     -1         0         3        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To load dataset\n",
    "df=pd.read_csv(\"bank.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          0\n",
       "job          0\n",
       "marital      0\n",
       "education    0\n",
       "default      0\n",
       "balance      0\n",
       "housing      0\n",
       "loan         0\n",
       "contact      0\n",
       "day          0\n",
       "month        0\n",
       "duration     0\n",
       "campaign     0\n",
       "pdays        0\n",
       "previous     0\n",
       "poutcome     0\n",
       "deposit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11162 entries, 0 to 11161\n",
      "Data columns (total 17 columns):\n",
      "age          11162 non-null int64\n",
      "job          11162 non-null int64\n",
      "marital      11162 non-null int64\n",
      "education    11162 non-null int64\n",
      "default      11162 non-null int64\n",
      "balance      11162 non-null int64\n",
      "housing      11162 non-null int64\n",
      "loan         11162 non-null int64\n",
      "contact      11162 non-null int64\n",
      "day          11162 non-null int64\n",
      "month        11162 non-null int64\n",
      "duration     11162 non-null int64\n",
      "campaign     11162 non-null int64\n",
      "pdays        11162 non-null int64\n",
      "previous     11162 non-null int64\n",
      "poutcome     11162 non-null int64\n",
      "deposit      11162 non-null int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "#check all details\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate Independent variable(input variable) X and dependent variable \n",
    "#Y(target/output)\n",
    "X=df.drop(\"deposit\",axis=1) #to store all inputs hold in X variable apart from\n",
    "#deposit\n",
    "Y=df[\"deposit\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split()\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split our dataset in train test of 70% & 30%\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model): #create_model() user defined function and passing\n",
    "    #argument and return value\n",
    "    model.fit(X_train,Y_train) #train the model\n",
    "    y_pred=model.predict(X_test) #test the model Y_pred=1/(1+e-(X))\n",
    "    print(classification_report(Y_test,y_pred))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Ensembling Technique : -\n",
    "#1. Naive Aggregation\n",
    "\n",
    "#we train the same dataset df(bank.csv) on 3 different types og algorithm\n",
    "#of classification (1. Logistic regression ,2. DecisionTreeClassifier(Gini index),\n",
    "#3. DecisionTreeClassifier(criterion=\"entropy\"))\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#create the object of Logistic regression \n",
    "lr=LogisticRegression()\n",
    "#create the object of DecisionTreeClassifier\n",
    "dt1=DecisionTreeClassifier()  #by defualt gini index method used\n",
    "#create the object of DecisionTreeClassifier (Entropy)\n",
    "dt2=DecisionTreeClassifier(criterion=\"entropy\")  #entropy otherwise gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A list consists of multiple tuples and each tuples the first argument\\nhas to be a string that is a name of model and second argument has to be a \\nobject of model'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic steps : -\n",
    "#Create a model List : - name model_list it a user defined list object\n",
    "model_list=[(\"Logistic\",lr),(\"DecisionGini\",dt1),(\"DecisionEntropy\",dt2)]\n",
    "'''A list consists of multiple tuples and each tuples the first argument\n",
    "has to be a string that is a name of model and second argument has to be a \n",
    "object of model'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we need Naive aggregation then we importing class\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of VotingClassifier class\n",
    "vc=VotingClassifier(estimators=model_list) #by default hard voting\n",
    "#here in estimators parameters , pass list of model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1760\n",
      "           1       0.80      0.80      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Logistic', LogisticRegression()),\n",
       "                             ('DecisionGini', DecisionTreeClassifier()),\n",
       "                             ('DecisionEntropy',\n",
       "                              DecisionTreeClassifier(criterion='entropy'))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hard Voting \n",
    "#Lets call create_model() user defined function\n",
    "create_model(vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall 0.81 good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soft voting : -\n",
    "#create object of VotingClassifier class\n",
    "vc1=VotingClassifier(estimators=model_list,voting=\"soft\")\n",
    "#by default hard voting if not mension second parameter voting=\"soft\"\n",
    "#here in estimators parameters , pass list of model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1760\n",
      "           1       0.80      0.81      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.81      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Logistic', LogisticRegression()),\n",
       "                             ('DecisionGini', DecisionTreeClassifier()),\n",
       "                             ('DecisionEntropy',\n",
       "                              DecisionTreeClassifier(criterion='entropy'))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function\n",
    "create_model(vc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall =0.81 which are same as hard voting \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Bagging\\n   2. Pasting\\n   3. Random-forest tree'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply Bootstrapping Ensembling Technique on same data set bank.csv\n",
    "#There are 3 types of Bootstrpping Tech .\n",
    "'''1. Bagging\n",
    "   2. Pasting\n",
    "   3. Random-forest tree'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In Naive aggregation : We choose a different types of model or you can\\nsay different types of Algorithm .\\nBut In Bootstrapping Aggregation , We choose only one type of Algorithm and\\neach of those algorithm a train with different samples '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''In Naive aggregation : We choose a different types of model or you can\n",
    "say different types of Algorithm .\n",
    "But In Bootstrapping Aggregation , We choose only one type of Algorithm and\n",
    "each of those algorithm a train with different samples '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Bagging : \n",
    "#create the object of BaggingClassifier class ,before create the object call\n",
    "#inbuilt class BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object of BaggingClassifier class\n",
    "bc=BaggingClassifier(LogisticRegression(),n_estimators=10,max_samples=780,random_state=1)\n",
    "#first agrument :  what type of algorithm be need to use Lets we choose to use\n",
    "#Logistic Regression  \n",
    "#2. second argument : How many Logistic regression algo. means no. of \n",
    "#instance  of logistic regression ,here take 10 logistic regression algo.\n",
    "#so we have to pass an argument called n_estimators \n",
    "#third argument : Each of them will be train on each sample\n",
    "# We take 10 records in each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7813, 16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79      1760\n",
      "           1       0.78      0.72      0.75      1589\n",
      "\n",
      "    accuracy                           0.77      3349\n",
      "   macro avg       0.77      0.77      0.77      3349\n",
      "weighted avg       0.77      0.77      0.77      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(), max_samples=780,\n",
       "                  random_state=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function\n",
    "create_model(bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pasting : - use same class BaggingClassifier class\n",
    "#create the object of BaggingClassifier class for pasting\n",
    "bc1=BaggingClassifier(LogisticRegression(),n_estimators=10,max_samples=780,random_state=1,bootstrap=False)\n",
    "#bootstrap=True bydefault means mension Bagging if mension bootstrap=False\n",
    "#then it is pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79      1760\n",
      "           1       0.77      0.73      0.75      1589\n",
      "\n",
      "    accuracy                           0.77      3349\n",
      "   macro avg       0.77      0.77      0.77      3349\n",
      "weighted avg       0.77      0.77      0.77      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(), bootstrap=False,\n",
       "                  max_samples=780, random_state=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function\n",
    "create_model(bc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive aggr. has given as good result (0.81)but bagging ans pasting have \n",
    "#not given a good result(0.73) as compared to naive aggr. in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random-Forest Tree : It is also  a subtype of Bootstrapping Ensembling tech.\n",
    "#Instead of logistic regression , We want to choose DecisionTreeClssifier \n",
    "#algo. It is called random forest tree ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If we are using multiple decision trees and each of the trees are getting \\ntrain on different samples that becomes a random forest algorithm '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use same class BaggingClassifier class for random forest tree\n",
    "#create the object of BaggingClassifier class for random forest tree\n",
    "bc2=BaggingClassifier(DecisionTreeClassifier(),n_estimators=10,max_samples=780,random_state=1)\n",
    "\n",
    "'''If we are using multiple decision trees and each of the trees are getting \n",
    "train on different samples that becomes a random forest algorithm '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      1760\n",
      "           1       0.80      0.77      0.78      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.80      0.80      0.80      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_samples=780,\n",
       "                  random_state=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function\n",
    "create_model(bc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11162, 16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
       "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
       "       'previous', 'poutcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#But Apart for that , we can separately call you can separately import\n",
    "#an another class called RandomForestClassifier class\n",
    "#import RandomForestClassifier class\n",
    "from sklearn.ensemble import RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of RandomForestClassifier  class\n",
    "rf=RandomForestClassifier(n_estimators=10,max_features=8,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      1760\n",
      "           1       0.82      0.83      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=8, n_estimators=10, random_state=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function\n",
    "create_model(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are passing different parameters : -\\n1. n_estimators : - How many trees we want .\\n2. max_features : - each of the trees will be trained on max 8 features \\nbasically in your dataframe , There are lot of features not just 8  but\\nlot of features but at a time only one tree will be train with max of \\n8 features'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In randomforestclassifier : -\n",
    "'''There are passing different parameters : -\n",
    "1. n_estimators : - How many trees we want .\n",
    "2. max_features : - each of the trees will be trained on max 8 features \n",
    "basically in your dataframe , There are lot of features not just 8  but\n",
    "lot of features but at a time only one tree will be train with max of \n",
    "8 features'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in max_features not more than 10  ,but can be less than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. stacking Ensembling :-\n",
    "#install package for stacking because no class define for stacking in sklearn \n",
    "#package\n",
    "#install package mlxtend for stacking \n",
    "\n",
    "#!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Stacking Ensembling Technique\n",
    "from mlxtend.classifier import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stacking is a Extra steps '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''4. Stacking is a Extra steps '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we train the same dataset df(bank.csv) on 3 different types og algorithm\n",
    "#of classification (1. Logistic regression ,2. DecisionTreeClassifier(Gini index),\n",
    "#3. DecisionTreeClassifier(criterion=\"entropy\")) as similar to Naive aggregation\n",
    "\n",
    "#create the object of Logistic regression \n",
    "lr=LogisticRegression()\n",
    "#create the object of DecisionTreeClassifier\n",
    "dt1=DecisionTreeClassifier()  #by defualt gini index method used\n",
    "#create the object of DecisionTreeClassifier (Entropy)\n",
    "dt2=DecisionTreeClassifier(criterion=\"entropy\")  #entropy otherwise gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a model List : - name model_list it a user defined list object\n",
    "model_list=[lr,dt1,dt2] #we create only list of model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta=LogisticRegression() # here we take metaclassifier is Logistic regression\n",
    "#means o/p of all prob's value of all algo. is a input of Meta classifier algo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the object of StackingClassifier class and pass the no. of arguments/\n",
    "#parameters\n",
    "sc=StackingClassifier(classifiers=model_list,meta_classifier=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1760\n",
      "           1       0.81      0.81      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(classifiers=[LogisticRegression(), DecisionTreeClassifier(),\n",
       "                                DecisionTreeClassifier(criterion='entropy')],\n",
       "                   meta_classifier=LogisticRegression())"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function \n",
    "create_model(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest tree given recall=0.83 in bank.csv dataset \n",
    "#naive aggr. recall =0.81\n",
    "#stacking recall=0.81"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
