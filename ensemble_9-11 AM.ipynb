{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensembling Technique \n",
    "#1. Naive Aggregation\n",
    "#a. hard voting  b. soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bank.csv \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To load csv file\n",
    "df=pd.read_csv(\"bank.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2343</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1270</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2476</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>673</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0   59    0        1          1        0     2343        1     0        2   \n",
       "1   56    0        1          1        0       45        0     0        2   \n",
       "2   41    9        1          1        0     1270        1     0        2   \n",
       "3   55    7        1          1        0     2476        1     0        2   \n",
       "4   54    0        1          2        0      184        0     0        2   \n",
       "\n",
       "   day  month  duration  campaign  pdays  previous  poutcome  deposit  \n",
       "0    5      8      1042         1     -1         0         3        1  \n",
       "1    5      8      1467         1     -1         0         3        1  \n",
       "2    5      8      1389         1     -1         0         3        1  \n",
       "3    5      8       579         1     -1         0         3        1  \n",
       "4    5      8       673         2     -1         0         3        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          0\n",
       "job          0\n",
       "marital      0\n",
       "education    0\n",
       "default      0\n",
       "balance      0\n",
       "housing      0\n",
       "loan         0\n",
       "contact      0\n",
       "day          0\n",
       "month        0\n",
       "duration     0\n",
       "campaign     0\n",
       "pdays        0\n",
       "previous     0\n",
       "poutcome     0\n",
       "deposit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11162 entries, 0 to 11161\n",
      "Data columns (total 17 columns):\n",
      "age          11162 non-null int64\n",
      "job          11162 non-null int64\n",
      "marital      11162 non-null int64\n",
      "education    11162 non-null int64\n",
      "default      11162 non-null int64\n",
      "balance      11162 non-null int64\n",
      "housing      11162 non-null int64\n",
      "loan         11162 non-null int64\n",
      "contact      11162 non-null int64\n",
      "day          11162 non-null int64\n",
      "month        11162 non-null int64\n",
      "duration     11162 non-null int64\n",
      "campaign     11162 non-null int64\n",
      "pdays        11162 non-null int64\n",
      "previous     11162 non-null int64\n",
      "poutcome     11162 non-null int64\n",
      "deposit      11162 non-null int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target means output variable : deposit\n",
    "#Separate input and output variables from dataframe\n",
    "X=df.drop(\"deposit\",axis=1) \n",
    "Y=df[\"deposit\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train_Test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create user defined function\n",
    "def create_model(model): #passing arguments model : object\n",
    "    model.fit(X_train,Y_train) #train the model with 70% data\n",
    "    Y_pred=model.predict(X_test) #test the model\n",
    "    print(classification_report(Y_test,Y_pred))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensembling Technique \n",
    "#1. Naive Aggregation \n",
    "#HArd Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the object of Logistic Regression \n",
    "lr=LogisticRegression()\n",
    "\n",
    "#create the object of DecisionTreeClassifier(Gini Index)\n",
    "dt1=DecisionTreeClassifier() #by defualt gini index\n",
    "\n",
    "#create the object of DecisionTreeClassifier(Entropy)\n",
    "dt2=DecisionTreeClassifier(criterion=\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A List consists of multiple tuples and each tuple the first argument hast to\\nbe a string that is a name of the model and second argument has to be a object\\nof model'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Begin with simple \n",
    "#create a Model List\n",
    "model_list=[(\"Logistic\",lr),(\"DT-GINI\",dt1),(\"DT-Entropy\",dt2)]\n",
    "'''A List consists of multiple tuples and each tuple the first argument hast to\n",
    "be a string that is a name of the model and second argument has to be a object\n",
    "of model'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the object of VotingClassifier \n",
    "vc1=VotingClassifier(estimators=model_list) #bydefault hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification_report inbuilt class\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1760\n",
      "           1       0.81      0.81      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Logistic', LogisticRegression()),\n",
       "                             ('DT-GINI', DecisionTreeClassifier()),\n",
       "                             ('DT-Entropy',\n",
       "                              DecisionTreeClassifier(criterion='entropy'))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function\n",
    "create_model(vc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall=0.81 means good o/p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soft voting\n",
    "#Create the object of VotingClassifier \n",
    "vc2=VotingClassifier(estimators=model_list,voting=\"soft\") #otherwise hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1760\n",
      "           1       0.80      0.81      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Logistic', LogisticRegression()),\n",
       "                             ('DT-GINI', DecisionTreeClassifier()),\n",
       "                             ('DT-Entropy',\n",
       "                              DecisionTreeClassifier(criterion='entropy'))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function\n",
    "create_model(vc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same recall=0.81 in hard and soft voting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LECTURE DATE 13-JAN-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Bootstrapping : this is the 2nd Technique of Ensemblinh tech.\n",
    "#1. Bagging  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create object of BaggingClassifier class \n",
    "bc=BaggingClassifier(LogisticRegression(),n_estimators=5,max_samples=10,\n",
    "                     random_state=1) #bydefualt Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first argument in BaggingClassifier() : we need to pass what type of\n",
    "#Algorithm be need to use ,Lets I choose to use suppose Logistic Regression\n",
    "#n_estimators means 10 different logistic regression algo. running \n",
    "#each of them will be train on 10 sample \n",
    "#means There are 10 Logistic Reg. and each of then will be train on 10\n",
    "#samples may be 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.68      1760\n",
      "           1       0.65      0.74      0.69      1589\n",
      "\n",
      "    accuracy                           0.69      3349\n",
      "   macro avg       0.69      0.69      0.69      3349\n",
      "weighted avg       0.69      0.69      0.69      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(), max_samples=10,\n",
       "                  n_estimators=5, random_state=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function\n",
    "create_model(bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall =0.74 its good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Pasting \n",
    "#Create object of BaggingClassifier class \n",
    "bc2=BaggingClassifier(LogisticRegression(),n_estimators=5,max_samples=10,\n",
    "                     random_state=1,bootstrap=False) #bydefault bootstrap=True\n",
    "#means use Bagging , if select False means use pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.68      1760\n",
      "           1       0.65      0.74      0.69      1589\n",
      "\n",
      "    accuracy                           0.69      3349\n",
      "   macro avg       0.69      0.69      0.69      3349\n",
      "weighted avg       0.69      0.69      0.69      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(), bootstrap=False,\n",
       "                  max_samples=10, n_estimators=5, random_state=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create function\n",
    "create_model(bc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall same =0.74 means good but not best ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging and pasting not produced good result but Naive aggr. given good\n",
    "#score =0.81(hard or soft voting) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Random forest : instead of Logistic regression ,We want to choose \n",
    "#DecisionTree , It is called Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create object of BaggingClassifier class \n",
    "bc3=BaggingClassifier(DecisionTreeClassifier(),n_estimators=10,max_samples=10,\n",
    "                     random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.90      0.74      1760\n",
      "           1       0.79      0.40      0.53      1589\n",
      "\n",
      "    accuracy                           0.67      3349\n",
      "   macro avg       0.71      0.65      0.64      3349\n",
      "weighted avg       0.70      0.67      0.64      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_samples=10,\n",
       "                  random_state=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function\n",
    "create_model(bc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier inbuilt class\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of RandomForestClassifier  means decisiontree use\n",
    "rfc=RandomForestClassifier(n_estimators=10,max_features=10,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84      1760\n",
      "           1       0.82      0.83      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=10, n_estimators=10, random_state=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function\n",
    "create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to pass n_extimators : means How many Trees we want \n",
    "#max_features : Each of the trees will be trained on max 10 features .\n",
    "#Basically in your dataframe , there are lot of features not just 10\n",
    "#but lot of features \n",
    "#max_features not more 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlxtend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking is actually an extra steps . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install mlxtend --channel conda-forge  in anoconda prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the object of Logistic Regression \n",
    "lr=LogisticRegression()\n",
    "\n",
    "#create the object of DecisionTreeClassifier(Gini Index)\n",
    "dt1=DecisionTreeClassifier() #by defualt gini index\n",
    "\n",
    "#create the object of DecisionTreeClassifier(Entropy)\n",
    "dt2=DecisionTreeClassifier(criterion=\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the list of model\n",
    "model_list=[lr,dt1,dt2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of meta class suppose take LogisticRegression() class\n",
    "meta=LogisticRegression()\n",
    "#meta user defined object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of StackingClassifier class and pass the arguments/paramters\n",
    "sc=StackingClassifier(classifiers=model_list,meta_classifier=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1760\n",
      "           1       0.80      0.81      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(classifiers=[LogisticRegression(), DecisionTreeClassifier(),\n",
       "                                DecisionTreeClassifier(criterion='entropy')],\n",
       "                   meta_classifier=LogisticRegression())"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function\n",
    "create_model(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Boosting :  \n",
    "#subtype of Boosting :-\n",
    "#.1 ADA Boosting : Adapter boosting\n",
    "#2. Gradient Boost\n",
    "#3. XG Boost : Extreme Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. ADA Boost :  its create a decision stump : \n",
    "#Decision stump means one root node and there are 2 leaf node\n",
    "#leaf node : means no child "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of AdaBoostClassifier \n",
    "ada=AdaBoostClassifier(n_estimators=100) #n_estimantors parameter<100 \n",
    "#n_estimators means no. of iteration and use algorithm : decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84      1760\n",
      "           1       0.83      0.80      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function\n",
    "create_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Gradient Boost : is the type of Boosting Algorithm , Basically this\n",
    "#tech. focus on short comings.\n",
    "#short comings means error \n",
    "#GB is not create a decision stump , this creates actualy create a decision \n",
    "# tree [fully grown tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object of GradientBoostingClassifier  class\n",
    "gbc=GradientBoostingClassifier(n_estimators=100) #not mension any algorithm\n",
    "#because DB use Decision tree\n",
    "#n_estimators means no. of iterations <=100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84      1760\n",
      "           1       0.81      0.86      0.83      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function\n",
    "create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. XGB : extreme Gradient Boosting : this is 3rd tech. of boosting tech. \n",
    "# XGB is a better version of gradient Boost  \n",
    "#why is a better version ? because XGB used all techniques\n",
    "#Advantages XGB vs GB \n",
    "#means Its use multithreading \n",
    "# It takes less memory space \n",
    "#its faster\n",
    "# It is very useful to handle huge amount of data \n",
    "# To handle Overfiiting situation automatically \n",
    "#To hangle outlier automatic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install the package first Because it is not define in sklearn package\n",
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of XGBClassifier class \n",
    "xg=XGBClassifier(n_estimators=100,reg_alpha=1)#reg_alpha=1 means to handle\n",
    "#automatic overfitting and outlier situation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85      1760\n",
      "           1       0.82      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=1, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function\n",
    "create_model(xg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
